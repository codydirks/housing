{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479a8d9b",
   "metadata": {},
   "source": [
    "# Plan of Attack\n",
    "\n",
    "In order to try and improve this model, there are a few areas that we want to investigate:\n",
    "- Changes to existing modeling approach\n",
    "- Changes to existing feature preprocessing\n",
    "- Feature engineering to add new (potentially better) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b51c1a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import pipeline, preprocessing, base\n",
    "\n",
    "from housing.config import DEMOGRAPHICS_PATH, SALES_PATH\n",
    "from housing.modeling.create_model import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0834779e",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "Just some initial exploration of the input dataset to make sure I understand some of it's basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7eca93e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21613, 43), (21613,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cols = [\n",
    "    \"price\",\n",
    "    \"bedrooms\",\n",
    "    \"bathrooms\",\n",
    "    \"sqft_living\",\n",
    "    \"sqft_lot\",\n",
    "    \"floors\",\n",
    "    \"waterfront\",\n",
    "    \"view\",\n",
    "    \"condition\",\n",
    "    \"grade\",\n",
    "    \"sqft_above\",\n",
    "    \"sqft_basement\",\n",
    "    \"yr_built\",\n",
    "    \"yr_renovated\",\n",
    "    \"zipcode\",\n",
    "    \"lat\",\n",
    "    \"long\",\n",
    "    \"sqft_living15\",\n",
    "    \"sqft_lot15\",\n",
    "]\n",
    "\n",
    "x, y = load_data(SALES_PATH, DEMOGRAPHICS_PATH, all_cols)\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434f0d7",
   "metadata": {},
   "source": [
    "- Assuming a default holdout set of 25%, this gives us 16,210 training samples and 5,403 holdout samples.\n",
    "- 43 columns is quite a few, indicating that simple linear models might struggle a bit due to the high dimensionality of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f6a388",
   "metadata": {},
   "source": [
    "# Helpers\n",
    "\n",
    "Utility functions to train a specified model on the specified feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "050a1d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "def build_pipeline(estimator: base.BaseEstimator) -> pipeline.Pipeline:\n",
    "    model = pipeline.make_pipeline(\n",
    "        preprocessing.RobustScaler(),\n",
    "        estimator\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(model: pipeline.Pipeline, cols: List[str]):\n",
    "    x, y = load_data(SALES_PATH, DEMOGRAPHICS_PATH, cols)\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "        x,\n",
    "        y,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    train_score = model.score(x_train, y_train)\n",
    "    test_score = model.score(x_test, y_test)\n",
    "\n",
    "    print(f\"Train score: {train_score:.4f}\")\n",
    "    print(f\"Test score: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba74f3",
   "metadata": {},
   "source": [
    "# First step: Recreate provided training method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4838b7",
   "metadata": {},
   "source": [
    "Standard training copied from provided `create_model.py` to see what our existing production model performance is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18b7abe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.8414\n",
      "Test score: 0.7281\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "cols = [\n",
    "    'price',\n",
    "    'bedrooms',\n",
    "    'bathrooms',\n",
    "    'sqft_living',\n",
    "    'sqft_lot',\n",
    "    'floors',\n",
    "    'sqft_above',\n",
    "    'sqft_basement',\n",
    "    'zipcode'\n",
    "]\n",
    "\n",
    "model = build_pipeline(neighbors.KNeighborsRegressor())\n",
    "\n",
    "train_and_evaluate(model, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6dfcd",
   "metadata": {},
   "source": [
    "# Baseline Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e02412a",
   "metadata": {},
   "source": [
    "Linear regression is probably too simplistic for this sort of problem, but it has the advantage of being _interpretable_, which can often be quite helpful when trying to understand a dataset (or present it to a client in a way that is understandable by them). Let's start there to at least get a good baseline for our model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31b39477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7319\n",
      "Test score: 0.7190\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "model = build_pipeline(linear_model.LinearRegression())\n",
    "\n",
    "train_and_evaluate(model, cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60c6fb",
   "metadata": {},
   "source": [
    "The easiest thing to do to try and improve the model is provide more columns of data, to see if more information improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb3447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7939\n",
      "Test score: 0.7890\n"
     ]
    }
   ],
   "source": [
    "all_cols = [\n",
    "    \"price\",\n",
    "    \"bedrooms\",\n",
    "    \"bathrooms\",\n",
    "    \"sqft_living\",\n",
    "    \"sqft_lot\",\n",
    "    \"floors\",\n",
    "    \"waterfront\",\n",
    "    \"view\",\n",
    "    \"condition\",\n",
    "    \"grade\",\n",
    "    \"sqft_above\",\n",
    "    \"sqft_basement\",\n",
    "    \"yr_built\",\n",
    "    \"yr_renovated\",\n",
    "    \"zipcode\",\n",
    "    \"lat\",\n",
    "    \"long\",\n",
    "    \"sqft_living15\",\n",
    "    \"sqft_lot15\",\n",
    "]\n",
    "\n",
    "model = build_pipeline(linear_model.LinearRegression())\n",
    "\n",
    "train_and_evaluate(model, all_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70617c22",
   "metadata": {},
   "source": [
    "That's already better, but we can probably continue to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df99f37",
   "metadata": {},
   "source": [
    "# An Obvious Next Step: A Regularized Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f000fb",
   "metadata": {},
   "source": [
    "Adding regularization to an existing linear model can sometimes be an easy way to improve model performance, typically by preventing overfitting by penalizing the model for large coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ab7d3dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.7932\n",
      "Test score: 0.7884\n"
     ]
    }
   ],
   "source": [
    "model = build_pipeline(linear_model.Ridge(alpha=1.0))\n",
    "\n",
    "train_and_evaluate(model, all_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1274927",
   "metadata": {},
   "source": [
    "Not much difference from the simple linear model - this would indicate to me that we should try a wholly different approach than the standard linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d3ed8b",
   "metadata": {},
   "source": [
    "# A More Complex Modeling Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df1292c",
   "metadata": {},
   "source": [
    "Since we have a lot of features, especially after joining in demographic data, I often find it's best to take and ensemble approach that allows the model to determine the most important features. Random forests in particular allow for the handling of nonlinear relationships between features and targets, while still remaining fairly robust to over-fitting due to the ensemble nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7ddcceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9841\n",
      "Test score: 0.8774\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "model = build_pipeline(\n",
    "    ensemble.RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE)\n",
    ")\n",
    "\n",
    "train_and_evaluate(model, all_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2eb086",
   "metadata": {},
   "source": [
    "Much better! We improved by ~9 percentage points over our initial baseline. Though we are very clearly overfitting to the training data, since our performance on the holdout set is over 10 percentage points lower. This could be due to inherent differences in the training/testing split (i.e. we have some bias and/or differences between the two datasets, rather than being similar distributions). To test this hypothesis, let's try some k-fold cross-validation (which should hopefully eliminate discrepancies in the training/test set) to see if that improves our test score at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41f02357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average train score: 0.9832\n",
      "Average test score: 0.8844\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_with_cross_validation(model: pipeline.Pipeline, cols: List[str], cv: int = 5):\n",
    "    x, y = load_data(SALES_PATH, DEMOGRAPHICS_PATH, cols)\n",
    "\n",
    "    cv_results = model_selection.cross_validate(\n",
    "        model,\n",
    "        x,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    print(f\"Average train score: {cv_results['train_score'].mean():.4f}\")\n",
    "    print(f\"Average test score: {cv_results['test_score'].mean():.4f}\")\n",
    "\n",
    "model = build_pipeline(\n",
    "    ensemble.RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE)\n",
    ")\n",
    "\n",
    "train_and_evaluate_with_cross_validation(model, all_cols, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f7f940",
   "metadata": {},
   "source": [
    "Only very slightly better - it appears that our `RandomForestRegressor` is responsible for the over-fitting.\n",
    "\n",
    "<br>\n",
    "\n",
    "If I were to continue to diagnose this over-fitting (which can be quite time-consuming, so I'm not actually going to), I would set up a grid search to do some hyperparameter tuning on the `RandomForestRegressor`, probably targeting a few key hyperparameters like `n_estimators`, `max_depth`, `max_features`, `min_samples_split`, and `min_samples_leaf`. I could even set up a custom metric to search for the hyperparameters that minimize the difference between the train and test scores, just to try and find the parameters that minimize overfitting. This may not necessarily be the \"best\" model (as measured by performance on the holdout set), but it would still be informative to understand the root cause of overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66b4e2",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d8c01d",
   "metadata": {},
   "source": [
    "Despite the overfitting, I'm still pretty happy with the performance of the model on holdout data. To see if we can continue to increase performance though, let's try engineering some additional features and using the same `RandomForestRegressor` model as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1fb0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9843\n",
      "Test score: 0.8759\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    SALES_PATH,\n",
    "    dtype={'zipcode': str}\n",
    ")\n",
    "demographics = pd.read_csv(\n",
    "    DEMOGRAPHICS_PATH,\n",
    "    dtype={'zipcode': str}\n",
    ")\n",
    "\n",
    "data = data.merge(\n",
    "    demographics,\n",
    "    on=\"zipcode\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "data[\"date\"] = data[\"date\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "# Some simple boolean flags to better capture common house features\n",
    "data[\"is_renovated\"] = (data[\"yr_renovated\"] > 0).astype(int) \n",
    "data[\"has_basement\"] = (data[\"sqft_basement\"] > 0).astype(int)\n",
    "# Some other possibly useful real-estate features\n",
    "data[\"total_rooms\"] = data[\"bedrooms\"] + data[\"bathrooms\"]\n",
    "data[\"living_to_lot_ratio\"] = data[\"sqft_living\"] / data[\"sqft_lot\"]\n",
    "\n",
    "# Price per sqft is a common real-estate metric, but including it here enables the model to directly learn the price due\n",
    "# to the combination of this feature and sqft_living, rather than having to infer it indirectly.\n",
    "# data[\"price_per_sqft\"] = data[\"price\"] / data[\"sqft_living\"]\n",
    "\n",
    "\n",
    "# Some time/seasonal features\n",
    "data[\"age\"] = data[\"date\"].dt.year - data[\"yr_built\"]\n",
    "data[\"renovated_age\"] = np.where(\n",
    "    data[\"yr_renovated\"] > 0,\n",
    "    data[\"date\"].dt.year - data[\"yr_renovated\"],\n",
    "    data[\"age\"]\n",
    ")\n",
    "data[\"month_sold\"] = data[\"date\"].dt.month\n",
    "\n",
    "data[\"mean_price_zipcode\"] = data.groupby(\"zipcode\")[\"price\"].transform(\"mean\")\n",
    "\n",
    "# Offset by a month to better align with \"seasons\"\n",
    "# (i.e. winter = Dec, Jan, Feb, spring = Mar, Apr, May, etc)\n",
    "data[\"season_sold\"] = (data[\"month_sold\"] % 12 // 3) + 1  # 1 = Winter, 2 = Spring, 3 = Summer, 4 = Fall\n",
    "\n",
    "y = data.pop(\"price\")\n",
    "x = data.drop(columns=[\"date\", \"id\"])\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    x,\n",
    "    y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "model = build_pipeline(\n",
    "    ensemble.RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE)\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "train_score = model.score(x_train, y_train)\n",
    "test_score = model.score(x_test, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score:.4f}\")\n",
    "print(f\"Test score: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa08cd92",
   "metadata": {},
   "source": [
    "Not much better - I interpret this result as the `RandomForestRegressor` already doing a good job of picking out the sorts of non-linearities that these additional features describe just using the base set of columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ffeb7",
   "metadata": {},
   "source": [
    "# Feature Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6792437c",
   "metadata": {},
   "source": [
    "The `RobustScaler` is typically pretty good at properly scaling features to improve model training, but there are a few other common options available in `scikit-learn`:\n",
    "- `RobustScaler`: Scales relative to interquartile range (IQR), to better avoid outliers\n",
    "- `StandardScaler`: Translates features into z-space (i.e. std. devs. relative to feature mean)\n",
    "- `MinMaxScaler`: Linearly scales the features in the range (min, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2076de56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler Model Results:\n",
      "Train score: 0.9843\n",
      "Test score: 0.8759\n"
     ]
    }
   ],
   "source": [
    "robust_scaler_model = pipeline.make_pipeline(\n",
    "    preprocessing.RobustScaler(),\n",
    "    ensemble.RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE)\n",
    ")\n",
    "\n",
    "robust_scaler_model.fit(x_train, y_train)\n",
    "train_score = robust_scaler_model.score(x_train, y_train)\n",
    "test_score = robust_scaler_model.score(x_test, y_test)\n",
    "\n",
    "print(\"RobustScaler Model Results:\")\n",
    "print(f\"Train score: {train_score:.4f}\")\n",
    "print(f\"Test score: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "73a65a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler Model Results:\n",
      "Train score: 0.9843\n",
      "Test score: 0.8760\n"
     ]
    }
   ],
   "source": [
    "standard_scaler_model = pipeline.make_pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    ensemble.RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE)\n",
    ")\n",
    "standard_scaler_model.fit(x_train, y_train)\n",
    "train_score = standard_scaler_model.score(x_train, y_train)\n",
    "test_score = standard_scaler_model.score(x_test, y_test)\n",
    "\n",
    "print(\"StandardScaler Model Results:\")\n",
    "print(f\"Train score: {train_score:.4f}\")\n",
    "print(f\"Test score: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0bea55dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler Model Results:\n",
      "Train score: 0.9843\n",
      "Test score: 0.8759\n"
     ]
    }
   ],
   "source": [
    "minmax_scaler_model = pipeline.make_pipeline(\n",
    "    preprocessing.MinMaxScaler(),\n",
    "    ensemble.RandomForestRegressor(n_estimators=100, random_state=RANDOM_STATE)\n",
    ")\n",
    "minmax_scaler_model.fit(x_train, y_train)\n",
    "train_score = minmax_scaler_model.score(x_train, y_train)\n",
    "test_score = minmax_scaler_model.score(x_test, y_test) \n",
    "\n",
    "print(\"MinMaxScaler Model Results:\")\n",
    "print(f\"Train score: {train_score:.4f}\")\n",
    "print(f\"Test score: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9edad98",
   "metadata": {},
   "source": [
    "Again, not much change here, indicating that the specifics of the feature pre-processing aren't really driving the modeling performance here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194f972d",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "We've done a pretty quick and basic investigation into some different modeling approaches here. Below is a summary of our findings:\n",
    "- Using a simple linear regression model, we got a baseline performance of R^2 = 0.719.\n",
    "- This is similar to the performance of the current production model (R^2 = 0.728).\n",
    "- We were able to improve this linear regression (R^2 = 0.789) simply by providing more columns to the model - more features gives the model more information.\n",
    "- Adding in some regularization to this linear model doesn't improve performance much.\n",
    "- Switching to a more complex model (a random forest regressor) gave us a big jump in performance (R^2 = 0.877), due to random forest's ability to determine the most important features.\n",
    "- There appears to be some overfitting which wasn't resolved by introducing some cross-validation\n",
    "- Additional feature engineering and/or different feature preprocessing doesn't seem to make much of a difference, indicating that the random forest is already picking up on the non-linear relationships between the features and the target home price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64700b2",
   "metadata": {},
   "source": [
    "# Next Steps/Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315dc64a",
   "metadata": {},
   "source": [
    "All of the above work was done with the existing dataset in mind - a larger project focused on improving the client's model would almost certainly involve investigating additional datasets that could enrich the current features and improve the model's ability to determine home prices. To that end, I would start by attempting to source the following additional datasets, ordered by most-useful to least-useful:\n",
    "- Additional housing sales data for this same region spanning different years: the current dataset only spans a small ~1-year time range, so our ability to generalize beyond this time frame is limited. Housing markets often have large-scale fluctuations over time, so getting a larger time-range of data would let us better pick up on both seasonal and multi-year trends in home prices.\n",
    "- Additional housing sales data from other regions: while housing markets do differ regionally, there are (hopefully) general trends that apply across markets, so having additional data spanning different markets (and appropriately encoding that spatial information into the model) would still allow us to build a model of home prices that generalizes well across regions.\n",
    "- More granular demographic information: Zipcode-level demographics are clearly useful for this model, but FIPS- or census-tract-level demographics could allow the model to pick up even finer-grained spatial information in the housing market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a6bdf5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housing-notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
